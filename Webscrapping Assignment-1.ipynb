{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d1f87d",
   "metadata": {},
   "source": [
    "1) Write a python program to display all the header tags from wikipedia.org and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce077dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\rama krishna\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rama krishna\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rama krishna\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\rama krishna\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rama krishna\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rama krishna\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rama krishna\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rama krishna\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c65a1682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Headers\n",
      "0  Wikipedia\\n\\nThe Free Encyclopedia\n",
      "1            1 000 000+\\n\\n\\narticles\n",
      "2              100 000+\\n\\n\\narticles\n",
      "3               10 000+\\n\\n\\narticles\n",
      "4                1 000+\\n\\n\\narticles\n",
      "5                  100+\\n\\n\\narticles\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.wikipedia.org/'\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "header_tags = [header.text.strip() for header in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])]\n",
    "df = pd.DataFrame({'Headers': header_tags})\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b485b",
   "metadata": {},
   "source": [
    "2) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd22499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://currentaffairs.adda247.com/list-of-presidents-of-india/'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "   \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    table = soup.find('table', class_='table table-bordered table-striped')\n",
    "    \n",
    "    names = []\n",
    "    terms = []\n",
    "    \n",
    "   \n",
    "    for row in rows:\n",
    "       \n",
    "        if len(columns) == 2:\n",
    "            name = columns[0].text.strip()\n",
    "            term = columns[1].text.strip()\n",
    "            names.append(name)\n",
    "            terms.append(term)\n",
    "    \n",
    "    df = pd.DataFrame({'Name': names, 'Term of Office': terms})\n",
    "    \n",
    "    print(df)\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4998088",
   "metadata": {},
   "source": [
    "3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "c) Top 10 ODI bowlers along with the records of their team andrating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0910a24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Teams:\n",
      "               Team Matches Points Rating\n",
      "0    Australia\\nAUS      27  3,112    115\n",
      "1     Pakistan\\nPAK      27  3,102    115\n",
      "2        India\\nIND      40  4,558    114\n",
      "3      England\\nENG      28  2,942    105\n",
      "4  South Africa\\nSA      23  2,386    104\n",
      "5   New Zealand\\nNZ      31  3,110    100\n",
      "6   Bangladesh\\nBAN      33  3,107     94\n",
      "7     Sri Lanka\\nSL      37  3,448     93\n",
      "8  Afghanistan\\nAFG      21  1,687     80\n",
      "9   West Indies\\nWI      38  2,582     68\n",
      "\n",
      "Top 10 ODI Batsmen:\n",
      "                 Batsman Team Rating\n",
      "0             Babar Azam  PAK    863\n",
      "1           Shubman Gill  IND    759\n",
      "2  Rassie van der Dussen   SA    745\n",
      "3           David Warner  AUS    739\n",
      "4            Imam-ul-Haq  PAK    735\n",
      "5           Harry Tector  IRE    726\n",
      "6        Quinton de Kock   SA    721\n",
      "7            Virat Kohli  IND    715\n",
      "8           Rohit Sharma  IND    707\n",
      "9           Fakhar Zaman  PAK    705\n",
      "\n",
      "Top 10 ODI Bowlers:\n",
      "             Bowler Team Rating\n",
      "0    Josh Hazlewood  AUS    692\n",
      "1    Mitchell Starc  AUS    666\n",
      "2       Trent Boult   NZ    666\n",
      "3        Adam Zampa  AUS    663\n",
      "4        Matt Henry   NZ    658\n",
      "5  Mujeeb Ur Rahman  AFG    657\n",
      "6     Kuldeep Yadav  IND    656\n",
      "7       Rashid Khan  AFG    655\n",
      "8    Mohammed Siraj  IND    643\n",
      "9    Shaheen Afridi  PAK    635\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "team_url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "\n",
    "team_response = requests.get(team_url)\n",
    "\n",
    "if team_response.status_code == 200:\n",
    "\n",
    "    team_soup = BeautifulSoup(team_response.text, 'html.parser')\n",
    "    \n",
    "    teams = []\n",
    "    matches = []\n",
    "    points = []\n",
    "    ratings = []\n",
    "    \n",
    "    table = team_soup.find('table', class_='table')\n",
    "    rows = table.find_all('tr')[1:11] \n",
    "    \n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        team = columns[1].text.strip()\n",
    "        match = columns[2].text.strip()\n",
    "        point = columns[3].text.strip()\n",
    "        rating = columns[4].text.strip()\n",
    "        teams.append(team)\n",
    "        matches.append(match)\n",
    "        points.append(point)\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    top_10_teams_df = pd.DataFrame({\n",
    "        'Team': teams,\n",
    "        'Matches': matches,\n",
    "        'Points': points,\n",
    "        'Rating': ratings\n",
    "    })\n",
    "\n",
    "    print(\"Top 10 ODI Teams:\")\n",
    "    print(top_10_teams_df)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve data for teams. Status code: {team_response.status_code}\")\n",
    "\n",
    "batsmen_url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "\n",
    "batsmen_response = requests.get(batsmen_url)\n",
    "\n",
    "if batsmen_response.status_code == 200:\n",
    "\n",
    "    batsmen_soup = BeautifulSoup(batsmen_response.text, 'html.parser')\n",
    "    \n",
    "\n",
    "    batsmen = []\n",
    "    teams = []\n",
    "    ratings = []\n",
    "    \n",
    "    table = batsmen_soup.find('table', class_='table')\n",
    "    rows = table.find_all('tr')[1:11]  \n",
    "    \n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        batsman = columns[1].text.strip()\n",
    "        team = columns[2].text.strip()\n",
    "        rating = columns[3].text.strip()\n",
    "        batsmen.append(batsman)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    top_10_batsmen_df = pd.DataFrame({\n",
    "        'Batsman': batsmen,\n",
    "        'Team': teams,\n",
    "        'Rating': ratings\n",
    "    })\n",
    "\n",
    "    print(\"\\nTop 10 ODI Batsmen:\")\n",
    "    print(top_10_batsmen_df)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve data for batsmen. Status code: {batsmen_response.status_code}\")\n",
    "\n",
    "bowlers_url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "\n",
    "bowlers_response = requests.get(bowlers_url)\n",
    "\n",
    "if bowlers_response.status_code == 200:\n",
    "\n",
    "    bowlers_soup = BeautifulSoup(bowlers_response.text, 'html.parser')\n",
    "    \n",
    "    bowlers = []\n",
    "    teams = []\n",
    "    ratings = []\n",
    "    \n",
    "    table = bowlers_soup.find('table', class_='table')\n",
    "    rows = table.find_all('tr')[1:11]  \n",
    "    \n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        bowler = columns[1].text.strip()\n",
    "        team = columns[2].text.strip()\n",
    "        rating = columns[3].text.strip()\n",
    "        bowlers.append(bowler)\n",
    "        teams.append(team)\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    top_10_bowlers_df = pd.DataFrame({\n",
    "        'Bowler': bowlers,\n",
    "        'Team': teams,\n",
    "        'Rating': ratings\n",
    "    })\n",
    "\n",
    "\n",
    "    print(\"\\nTop 10 ODI Bowlers:\")\n",
    "    print(top_10_bowlers_df)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve data for bowlers. Status code: {bowlers_response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f7bff8",
   "metadata": {},
   "source": [
    "4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5a33d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Women's ODI Teams:\n",
      "                                                Name           Matches  \\\n",
      "0               1\\n                        \\n\\n\\n(0)    Josh Hazlewood   \n",
      "1       2\\n                                \\n\\n\\n(0)    Mitchell Starc   \n",
      "2  =\\n                                \\n\\n\\n\\n\\n(...       Trent Boult   \n",
      "3  4\\n                                \\n\\n\\n\\n\\n(...        Adam Zampa   \n",
      "4       5\\n                                \\n\\n\\n(0)        Matt Henry   \n",
      "5       6\\n                                \\n\\n\\n(0)  Mujeeb Ur Rahman   \n",
      "6  7\\n                                \\n\\n\\n\\n\\n(...     Kuldeep Yadav   \n",
      "7  8\\n                                \\n\\n\\n\\n\\n(...       Rashid Khan   \n",
      "8       9\\n                                \\n\\n\\n(0)    Mohammed Siraj   \n",
      "9      10\\n                                \\n\\n\\n(0)    Shaheen Afridi   \n",
      "\n",
      "  Points/Rating Rating  \n",
      "0           AUS    692  \n",
      "1           AUS    666  \n",
      "2            NZ    666  \n",
      "3           AUS    663  \n",
      "4            NZ    658  \n",
      "5           AFG    657  \n",
      "6           IND    656  \n",
      "7           AFG    655  \n",
      "8           IND    643  \n",
      "9           PAK    635  \n",
      "\n",
      "Top 10 Women's ODI Batting Players:\n",
      "                                                Name           Matches  \\\n",
      "0               1\\n                        \\n\\n\\n(0)    Josh Hazlewood   \n",
      "1       2\\n                                \\n\\n\\n(0)    Mitchell Starc   \n",
      "2  =\\n                                \\n\\n\\n\\n\\n(...       Trent Boult   \n",
      "3  4\\n                                \\n\\n\\n\\n\\n(...        Adam Zampa   \n",
      "4       5\\n                                \\n\\n\\n(0)        Matt Henry   \n",
      "5       6\\n                                \\n\\n\\n(0)  Mujeeb Ur Rahman   \n",
      "6  7\\n                                \\n\\n\\n\\n\\n(...     Kuldeep Yadav   \n",
      "7  8\\n                                \\n\\n\\n\\n\\n(...       Rashid Khan   \n",
      "8       9\\n                                \\n\\n\\n(0)    Mohammed Siraj   \n",
      "9      10\\n                                \\n\\n\\n(0)    Shaheen Afridi   \n",
      "\n",
      "  Points/Rating Rating  \n",
      "0           AUS    692  \n",
      "1           AUS    666  \n",
      "2            NZ    666  \n",
      "3           AUS    663  \n",
      "4            NZ    658  \n",
      "5           AFG    657  \n",
      "6           IND    656  \n",
      "7           AFG    655  \n",
      "8           IND    643  \n",
      "9           PAK    635  \n",
      "\n",
      "Top 10 Women's ODI All-rounders:\n",
      "                                                Name           Matches  \\\n",
      "0               1\\n                        \\n\\n\\n(0)    Josh Hazlewood   \n",
      "1       2\\n                                \\n\\n\\n(0)    Mitchell Starc   \n",
      "2  =\\n                                \\n\\n\\n\\n\\n(...       Trent Boult   \n",
      "3  4\\n                                \\n\\n\\n\\n\\n(...        Adam Zampa   \n",
      "4       5\\n                                \\n\\n\\n(0)        Matt Henry   \n",
      "5       6\\n                                \\n\\n\\n(0)  Mujeeb Ur Rahman   \n",
      "6  7\\n                                \\n\\n\\n\\n\\n(...     Kuldeep Yadav   \n",
      "7  8\\n                                \\n\\n\\n\\n\\n(...       Rashid Khan   \n",
      "8       9\\n                                \\n\\n\\n(0)    Mohammed Siraj   \n",
      "9      10\\n                                \\n\\n\\n(0)    Shaheen Afridi   \n",
      "\n",
      "  Points/Rating Rating  \n",
      "0           AUS    692  \n",
      "1           AUS    666  \n",
      "2            NZ    666  \n",
      "3           AUS    663  \n",
      "4            NZ    658  \n",
      "5           AFG    657  \n",
      "6           IND    656  \n",
      "7           AFG    655  \n",
      "8           IND    643  \n",
      "9           PAK    635  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def scrape_ranking_data(url, table_id):\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "       \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    \n",
    "        teams = []\n",
    "        matches = []\n",
    "        points = []\n",
    "        ratings = []\n",
    "\n",
    "        table = soup.find('table', id=table_id)\n",
    "\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            item1 = columns[0].text.strip()  \n",
    "            item2 = columns[1].text.strip()  \n",
    "            item3 = columns[2].text.strip()  \n",
    "            item4 = columns[3].text.strip()  \n",
    "\n",
    "            teams.append(item1)\n",
    "            matches.append(item2)\n",
    "            points.append(item3)\n",
    "            ratings.append(item4)\n",
    "\n",
    "       \n",
    "        df = pd.DataFrame({\n",
    "            'Name': teams,\n",
    "            'Matches': matches,\n",
    "            'Points/Rating': points,\n",
    "            'Rating': ratings\n",
    "        })\n",
    "\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "teams_url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "\n",
    "teams_table_id = 'standings-table'\n",
    "\n",
    "batsmen_url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "batsmen_table_id = 'batting-rankings'\n",
    "\n",
    "allrounders_url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "allrounders_table_id = 'all-round-rankings'\n",
    "\n",
    "women_teams_df = scrape_ranking_data(teams_url, teams_table_id)\n",
    "women_batsmen_df = scrape_ranking_data(batsmen_url, batsmen_table_id)\n",
    "women_allrounders_df = scrape_ranking_data(allrounders_url, allrounders_table_id)\n",
    "\n",
    "\n",
    "print(\"Top 10 Women's ODI Teams:\")\n",
    "print(women_teams_df)\n",
    "\n",
    "print(\"\\nTop 10 Women's ODI Batting Players:\")\n",
    "print(women_batsmen_df)\n",
    "\n",
    "print(\"\\nTop 10 Women's ODI All-rounders:\")\n",
    "print(women_allrounders_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a136e6",
   "metadata": {},
   "source": [
    "5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
    "make data frame\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78491191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.cnbc.com/world/?region=world'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "   \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "  \n",
    "    headlines = []\n",
    "    times = []\n",
    "    news_links = []\n",
    "    \n",
    "    news_articles = soup.find_all('div', class_='Card-titleContainer')\n",
    "    \n",
    "    for article in news_articles:\n",
    "        \n",
    "        headline = article.find('a', class_='Card-titleLink').text.strip()\n",
    "        headlines.append(headline)\n",
    "        \n",
    "        time = article.find('span', class_='Card-time').text.strip()\n",
    "        times.append(time)\n",
    "        \n",
    "       \n",
    "        news_link = 'https://www.cnbc.com' + article.find('a', class_='Card-titleLink')['href']\n",
    "        news_links.append(news_link)\n",
    "    \n",
    "\n",
    "    news_df = pd.DataFrame({\n",
    "        'Headline': headlines,\n",
    "        'Time': times,\n",
    "        'News Link': news_links\n",
    "    })\n",
    "    \n",
    "   \n",
    "    print(news_df)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2573ec",
   "metadata": {},
   "source": [
    "6) Write a python program to scrape the details \n",
    "https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53ebf71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Paper Title                                            Authors  \\\n",
      "0            1                                  Da Vinci Code,The   \n",
      "1            2               Harry Potter and the Deathly Hallows   \n",
      "2            3           Harry Potter and the Philosopher's Stone   \n",
      "3            4          Harry Potter and the Order of the Phoenix   \n",
      "4            5                               Fifty Shades of Grey   \n",
      "..         ...                                                ...   \n",
      "95          96                                          Ghost,The   \n",
      "96          97                     Happy Days with the Naked Chef   \n",
      "97          98              Hunger Games,The:Hunger Games Trilogy   \n",
      "98          99  Lost Boy,The:A Foster Child's Search for the L...   \n",
      "99         100  Jamie's Ministry of Food:Anyone Can Learn to C...   \n",
      "\n",
      "      Published Date  \n",
      "0         Brown, Dan  \n",
      "1      Rowling, J.K.  \n",
      "2      Rowling, J.K.  \n",
      "3      Rowling, J.K.  \n",
      "4       James, E. L.  \n",
      "..               ...  \n",
      "95    Harris, Robert  \n",
      "96     Oliver, Jamie  \n",
      "97  Collins, Suzanne  \n",
      "98      Pelzer, Dave  \n",
      "99     Oliver, Jamie  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "   \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    table = soup.find('table', class_='in-article sortable')\n",
    "\n",
    "    titles = []\n",
    "    authors = []\n",
    "    published_dates = []\n",
    "\n",
    "   \n",
    "    rows = table.find_all('tr')[1:] \n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        if len(columns) >= 3:\n",
    "            title = columns[0].text.strip()\n",
    "            author = columns[1].text.strip()\n",
    "            published_date = columns[2].text.strip()\n",
    "\n",
    "            titles.append(title)\n",
    "            authors.append(author)\n",
    "            published_dates.append(published_date)\n",
    "\n",
    "   \n",
    "    df = pd.DataFrame({\n",
    "        'Paper Title': titles,\n",
    "        'Authors': authors,\n",
    "        'Published Date': published_dates\n",
    "    })\n",
    "\n",
    "   \n",
    "    print(df)\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7fdc73",
   "metadata": {},
   "source": [
    "7) Write a python program to scrape mentioned details from dineout.co.inand make data frame\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5771d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "  \n",
    "    restaurant_names = []\n",
    "    cuisines = []\n",
    "    locations = []\n",
    "    ratings = []\n",
    "    image_urls = []\n",
    "    \n",
    "   \n",
    "    \n",
    "    for restaurant in restaurants:\n",
    "       \n",
    "        restaurant_name = restaurant.find('a', class_='restnt-name').text.strip()\n",
    "        restaurant_names.append(restaurant_name)\n",
    "        \n",
    "       \n",
    "        cuisine = restaurant.find('span', class_='double-line-ellipsis').text.strip()\n",
    "        cuisines.append(cuisine)\n",
    "        \n",
    "        \n",
    "        location = restaurant.find('span', class_='double-line-ellipsis').find_next_sibling('span').text.strip()\n",
    "        locations.append(location)\n",
    "        \n",
    "        \n",
    "        rating = restaurant.find('div', class_='restnt-rating').text.strip()\n",
    "        ratings.append(rating)\n",
    "        \n",
    "      \n",
    "        image_url = restaurant.find('div', class_='restnt-thumbnail').find('img')['data-src']\n",
    "        image_urls.append(image_url)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Restaurant Name': restaurant_names,\n",
    "        'Cuisine': cuisines,\n",
    "        'Location': locations,\n",
    "        'Ratings': ratings,\n",
    "        'Image URL': image_urls\n",
    "    })\n",
    "    \n",
    "   \n",
    "    print(df)\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
